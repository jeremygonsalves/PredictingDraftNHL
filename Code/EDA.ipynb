{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.12.2)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "import clean_reports\n",
    "#import preprocess_reports\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##from sentence_transformers import SentenceTransformer. # will be used for the bert transformer in the future\n",
    "# dataset location\n",
    "DATASET = \"/Users/jeremygonsalves/Documents/GitHub/PredictingDraftNHL/Data/prospect-data.csv\"\n",
    "print(\"Dataset saved as DATASET\")\n",
    "\n",
    "# load dataset into dataframe\n",
    "data = clean_reports.clean(DATASET, raw=True)\n",
    "\n",
    "data.head()\n",
    "DATASET=data\n",
    "\n",
    "#\n",
    "DATASET2023=data[data['Year'] == 2023]\n",
    "DATASET2022=data[data['Year'] ==2022]\n",
    "DATASET2021=data[data['Year'] == 2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_drafted_vs_ranking(data):\n",
    "    # Create the x-values range from the minimum to the maximum 'Drafted' position\n",
    "    x = np.arange(data['Drafted'].min(), data['Drafted'].max())     #creates an array of evenly spaced values from min ranked position to max pos\n",
    "    y = x\n",
    "\n",
    "    # Scatter plot of 'Drafted' vs 'Average Ranking'\n",
    "    plt.scatter(data['Drafted'], data['Average Ranking'])\n",
    "\n",
    "    # Plot a reference line y=x\n",
    "    plt.plot(x, y, 'y--', label=\"y=x\")\n",
    "    \n",
    "    plt.xlabel(\"Drafted Position\")\n",
    "    plt.ylabel(\"Average Ranking\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Predictive Average Ranking\")\n",
    "    plt.show()\n",
    "\n",
    "# Now you can call the function with the data you have\n",
    "print(\"-----------------\")\n",
    "print(\"For All Data\")\n",
    "print(plot_drafted_vs_ranking(DATASET))\n",
    "print(\"-----------------\")\n",
    "print(\"For 2022\")\n",
    "print(plot_drafted_vs_ranking(DATASET2022))\n",
    "print(\"-----------------\")\n",
    "print(\"For 2021\")\n",
    "print(plot_drafted_vs_ranking(DATASET2021))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOCKEY_POSITIONS = {\n",
    "    'C' : 'Center',\n",
    "    'D' : 'Defender',\n",
    "    'RW' : 'Right Wing',\n",
    "    'LW' : 'Left Wing',\n",
    "    'G' : 'Goalie'\n",
    "}\n",
    "\n",
    "# distribution of player positions\n",
    "data['Position'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = data.columns.str.match('Description')\n",
    "scouting_reports = data.columns[match]\n",
    "\n",
    "# Create a deep copy of data\n",
    "token_count = data.copy(deep=True)\n",
    "\n",
    "# Define a function to count tokens (words) using split\n",
    "def count_tokens(text):\n",
    "    if isinstance(text, str):\n",
    "        # Split the string by spaces and count the number of words\n",
    "        return len(text.split())\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function across all scouting report columns\n",
    "token_count[scouting_reports] = token_count[scouting_reports].applymap(count_tokens)\n",
    "\n",
    "average_token_count = token_count[scouting_reports].mean().sort_values()\n",
    "\n",
    "# Display the result\n",
    "print(average_token_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "bert_model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 2\n",
    "ncols = 4\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15,7))\n",
    "\n",
    "for index, report in enumerate(scouting_reports):\n",
    "    xx = token_count[report].values  \n",
    "    i, j = [array[0] for array in np.unravel_index([index], shape=(nrows,ncols))] \n",
    "    \n",
    "    ax[i, j].hist(xx, bins=50) \n",
    "    ax[i, j].set_title(report)  \n",
    "    \n",
    "    if xx[~np.isnan(xx)].max() > bert_model.max_seq_length:\n",
    "        ax[i, j].axvline(bert_model.max_seq_length, color='k', linestyle='dashed', linewidth=1)  # Add vertical line\n",
    "\n",
    "plt.suptitle(\"Distribution of Number of Tokens for Each Report\", fontsize=22)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Team'] != 'SEA'] #seattle is a new team as of 2021 having a 2021 second overall pick\n",
    "\n",
    "# keep data only to 2014-2022 (predict this year's class at a later time)\n",
    "data = data[data['Year'] <= 2022]\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert Transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = preprocessed_df.melt(\n",
    "    id_vars=['Year', 'Position', 'Height', 'Weight', 'Drafted', 'Team', 'Average Ranking', 'Name'],\n",
    "    value_vars=scouting_reports.tolist(),\n",
    "    var_name='reporter',  \n",
    "    value_name='text'\n",
    ").dropna(\n",
    "    subset=['text']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bert_embeddings_path = 'data/reports_with_bert_embeddings.csv'\n",
    "\n",
    "# Check if embeddings already exist\n",
    "if not os.path.exists(bert_embeddings_patpiph):\n",
    "    # Load the BERT model\n",
    "    bert_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "    # Generate BERT embeddings for the text in 'long_df'\n",
    "    bert_embeddings = bert_model.encode(long_df['text'].values)\n",
    "    bert_df = pd.DataFrame(bert_embeddings, columns=[f'bert{i}' for i in range(bert_embeddings.shape[1])])\n",
    "    long_df = pd.concat([long_df, bert_df], axis=1)\n",
    "    long_df.to_csv(bert_embeddings_path, index=False)\n",
    "    print(\"New File Was created\")\n",
    "else:\n",
    "    # Load the DataFrame with BERT embeddings\n",
    "    long_df = pd.read_csv(bert_embeddings_path)\n",
    "    bert_columns = [col for col in long_df.columns if col.startswith('bert')]\n",
    "    print(\"The BERT Embedding file was overriden\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
