{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mAttributeError: module 'ipykernel.kernelapp' has no attribute 'launch_new_instance'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "import clean_reports\n",
    "import preprocess_reports\n",
    "import setup_predictor\n",
    "from Model import *\n",
    "from train_test_predictor import train_and_test\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset location\n",
    "DATASET = \"data/prospect-data.csv\"\n",
    "\n",
    "# load dataset into dataframe\n",
    "data = clean_reports.clean(DATASET, raw=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up dataset\n",
    "# might have to look at dropping seattle in the future but for clustering it \n",
    "# should not matter\n",
    "data = data[data['Team'] != 'SEA']\n",
    "\n",
    "# try with only forwards\n",
    "# data = data[\n",
    "#     (data['Position'] == 'C') | \n",
    "#     (data['Position'] == 'LW') | \n",
    "#     (data['Position'] == 'RW')\n",
    "# ]\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOCKEY_WORDS = [\"usntdp\", \"ntdp\", \"development\", \"program\",\n",
    "                \"khl\", \"shl\", \"ushl\", \"ncaa\", \"ohl\", \"chl\", \"whl\", \"qmjhl\",\n",
    "                \"sweden\", \"russia\", \"usa\", \"canada\", \"ojhl\", \"finland\", \n",
    "                \"finnish\", \"swedish\", \"russian\", \"american\", \"wisconsin\",\n",
    "                \"michigan\", \"bc\", \"boston\", \"london\", \"bchl\", \"kelowna\",\n",
    "                \"liiga\", \n",
    "                \"portland\", \"minnesota\", \"ska\", \"frolunda\", \"sjhl\", \"college\",\n",
    "                \"center\", \"left\", \"right\", \"saginaw\", \"kelowna\", \"frolunda\",\n",
    "                \"slovakia\"]\n",
    "\n",
    "# scouting report columns\n",
    "mask = data.columns.str.match('Description')\n",
    "scouting_reports = data.columns[mask]\n",
    "\n",
    "# preprocess data with NLTK\n",
    "preprocessed_df = data.copy()\n",
    "for report in scouting_reports:\n",
    "    # skip columns with ALL missing values\n",
    "    if data[report].isnull().all():\n",
    "        continue\n",
    "    report_preprocessor = preprocess_reports.NltkPreprocessor(data[report])\n",
    "    preprocessed_df.loc[:,report] = report_preprocessor\\\n",
    "        .remove_names(data['Name'])\\\n",
    "        .remove_whitespace()\\\n",
    "        .remove_words(HOCKEY_WORDS)\\\n",
    "        .get_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform from wide to long data frame\n",
    "long_df = preprocessed_df.melt(\n",
    "    id_vars=['Year', 'Position', 'Height', 'Weight', 'Drafted', 'Team', 'Average Ranking', 'Name'],\n",
    "    value_vars=scouting_reports.tolist(),\n",
    "    var_name='reporter',  \n",
    "    value_name='text'\n",
    ").dropna(\n",
    "    subset=['text']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_embeddings_path = 'data/reports_with_embeddings.csv'\n",
    "if os.path.exists(openai_embeddings_path):\n",
    "    openai_df = pd.read_csv(openai_embeddings_path)\n",
    "    openai_df['embeddings'] = openai_df.embeddings.apply(eval).apply(np.array)\n",
    "    embeddings = np.vstack(openai_df['embeddings'].values).astype(np.float64)\n",
    "    openai_df['embeddings'] = [np.array(x, dtype=np.float64) for x in embeddings]\n",
    "\n",
    "    openai_cols = [f'openai{i}' for i in range(openai_df['embeddings'].iloc[0].shape[0])]\n",
    "\n",
    "    # create individual columns for each openai embedding\n",
    "    embeddings_df = pd.DataFrame(\n",
    "        np.concatenate([x.reshape(1,-1) for x in openai_df['embeddings']]),\n",
    "        columns=openai_cols\n",
    "    )\n",
    "\n",
    "    embeddings_df.loc[:,'player_name'] = openai_df['player_name']\n",
    "\n",
    "    full_df = pd.merge(preprocessed_df, embeddings_df, left_on='Name', right_on='player_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=20)\n",
    "\n",
    "X_pca = pca.fit_transform(\n",
    "    pd.DataFrame(\n",
    "        np.concatenate([x.reshape(1,-1) for x in openai_df['embeddings']]),\n",
    "    )\n",
    ")\n",
    "\n",
    "openai_pca_cols = [f'openai_pca{i}' for i in range(X_pca.shape[1])]\n",
    "\n",
    "embeddings_pca_df = pd.DataFrame(X_pca, columns=openai_pca_cols)\n",
    "\n",
    "embeddings_pca_df.loc[:,'player_name'] = openai_df['player_name']\n",
    "\n",
    "full_df = pd.merge(preprocessed_df, embeddings_pca_df, left_on='Name', right_on='player_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that every player has OpenAI embeddings\n",
    "full_df[full_df.columns[:20]].info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model architecture\n",
    "numeric_cols = ['Height', 'Weight'] + openai_pca_cols\n",
    "categorical_cols = ['Position']\n",
    "# text_cols = scouting_reports.tolist()\n",
    "text_cols = []\n",
    "lr_model = setup_predictor.setup(\n",
    "    numeric_cols=numeric_cols, \n",
    "    categorical_cols=categorical_cols,\n",
    "    text_cols=text_cols,\n",
    "    func=LogisticOrdinalRegression()\n",
    ")\n",
    "svm_model = setup_predictor.setup(\n",
    "    numeric_cols=numeric_cols, \n",
    "    categorical_cols=categorical_cols,\n",
    "    text_cols=text_cols,\n",
    "    func=SVC(probability=True)\n",
    ")\n",
    "\n",
    "mlp_model = setup_predictor.setup(\n",
    "    numeric_cols=numeric_cols, \n",
    "    categorical_cols=categorical_cols,\n",
    "    text_cols=text_cols,\n",
    "    func=MLPClassifier()\n",
    ")\n",
    "rf_model = setup_predictor.setup(\n",
    "    numeric_cols=numeric_cols, \n",
    "    categorical_cols=categorical_cols,\n",
    "    text_cols=text_cols,\n",
    "    func=RandomForestOrdinalClassifier()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_df[numeric_cols + categorical_cols + text_cols]\n",
    "y = full_df['Drafted']\n",
    "groups = full_df['Name']\n",
    "\n",
    "mean_df = pd.DataFrame(columns=['accuracy', 'f1', 'precision', 'recall'])\n",
    "std_df = pd.DataFrame(columns=['accuracy', 'f1', 'precision', 'recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = full_df[full_df['Year'] <= 2022].index.tolist()\n",
    "test_idx = full_df[full_df['Year'] == 2023].index.tolist()\n",
    "\n",
    "X_train = X.iloc[train_idx]\n",
    "y_train = y.iloc[train_idx]\n",
    "X_test = X.iloc[test_idx]\n",
    "y_test = y.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classification model\n",
    "param_grid = {\n",
    "    'clf__n_estimators' : np.arange(60, 110, 20).tolist(),\n",
    "    'clf__max_depth' : np.arange(20, 100, 20).tolist(),\n",
    "}\n",
    "\n",
    "label = 'OpenAI_rand_forest_2023_prediction'\n",
    "\n",
    "rf_metrics = train_and_test(rf_model, X_train, y_train, groups[train_idx], param_grid, notes=label)\n",
    "\n",
    "rf_mean = {k : np.mean(v) for k,v in rf_metrics.items()}\n",
    "rf_std = {k : np.std(v) for k,v in rf_metrics.items()}\n",
    "\n",
    "mean_df.loc[label] = pd.Series(rf_mean)\n",
    "std_df.loc[label] = pd.Series(rf_std)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2023 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try just one model fit\n",
    "rf_model = setup_predictor.setup(\n",
    "    numeric_cols=numeric_cols, \n",
    "    categorical_cols=categorical_cols,\n",
    "    text_cols=text_cols,\n",
    "    func=RandomForestOrdinalClassifier(n_estimators=80, max_depth=40, random_state=42)\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test set\n",
    "# since it is entire class of 2023, we can actually rank them\n",
    "y_test_pred = rf_model.predict(X_test).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = pd.DataFrame()\n",
    "foo.loc[:,'name'] = groups[test_idx]\n",
    "foo.loc[:,'ranking'] = y_test_pred + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.sort_values(by='ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
